# データ処理不等式

情報理論には **データ処理不等式 (data processing inequality)** という重要な定理がある．
定理の示す帰結は当たり前とも言える内容だが一般的に重要であり，ことITに関する議論ではよく忘れられているように思う．

確率変数 $X$, $Y$, $Z$ について，次のマルコフ連鎖が成立すると仮定しよう：
$$X \rightarrow Y \rightarrow \Z$$
情報理論の枠組の話なので確率変数になっているが，もっと身近に「データ」と言ってしまってよいかもしれない
（その場合，「データ」を覆う何か確率分布が存在すると思えばよい）．
この連鎖が意味するのはつまり，$X$ を処理して $Y$ を得て，その後 $X$ を**捨て**，
$Y$ のみから別の処理で $Z$ を得る，ということである．

このとき次の不等式が一般的に成り立つ：
$$I(X; Y) \geq I(X; Z)$$
$I(\cdot, \cdot)$は相互情報量である．
証明は $I(X; Y, Z)$ を分解すれば得られる：
$$\begin{array}{rcl} I(X; Y, Z) & = & I(X; Z) + I(X; Y | Z) \\ & = & I(X; Y) + I(X; Z | Y) \end{array}$$
ここでマルコフ連鎖の仮定から $X$ と $Z$ は $Y$ に関して条件付独立である．したがって $I(X; Z | Y) = 0$ である．
結局，
$$I(X; Z) + I(X; Y | Z) \\ & = & I(X; Y)$$
が得られるが， $I(X; Y | Z) \geq 0$ なので上記の不等式となる．
等号成立条件は $I(X; Y | Z) = 0$ であり，これは $Y$ と $Z$ が $X$ に関して本質的に同じ情報を保持していることを表す．
